

# PoseEstimation-CoreML

![platform-ios](https://img.shields.io/badge/platform-ios-lightgrey.svg)
![swift-version](https://img.shields.io/badge/swift-4.2-red.svg)
![lisence](https://img.shields.io/badge/license-MIT-black.svg)

ì—¬ëŸ¬ê°€ì§€ iOS+MLì˜ˆì œëŠ” [iOS Projects with ML Models ì €ì¥ì†Œ](https://github.com/motlabs/iOS-Proejcts-with-ML-Models)ì— ëª¨ì•„ì ¸ìˆìŠµë‹ˆë‹¤.<br>
ì´ í”„ë¡œì íŠ¸ëŠ” Core MLì„ ì‚¬ìš©í•˜ì—¬ Pose Estimationì„ ì‹¤í–‰ì‹œì¼œë³¸ ì˜ˆì œì…ë‹ˆë‹¤. <br>

| Jointed Keypoints                                            | Concatenated heatmap                                         |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| ![poseestimation-demo-joint.gif](https://github.com/tucan9389/PoseEstimation-CoreML/blob/master/resource/180801-poseestimation-demo.gif?raw=true) | ![poseestimation-demo-heatmap.gif](https://github.com/tucan9389/PoseEstimation-CoreML/blob/master/resource/180914-poseestimation-demo.gif?raw=true) |

ë¹„ë””ì˜¤ ì¶œì²˜: [https://www.youtube.com/watch?v=EM16LBKBEgI](https://www.youtube.com/watch?v=EM16LBKBEgI)

## ìš”êµ¬í™˜ê²½

- Xcode 9.2+
- iOS 11.0+
- Swift 4

## ëª¨ë¸ ì¤€ë¹„

Core MLìš© Pose Estimation ëª¨ë¸(`model_cpm.mlmodel`)<br>
> ~~â˜ Core ML ëª¨ë¸ì„ ì—¬ê¸°ì„œ ë‹¤ìš´ë°›ìœ¼ì„¸ìš”([model_cpm.mlmodel](https://github.com/edvardHua/PoseEstimationForMobile/tree/master/release/cpm_model) í˜¹ì€ [hourglass.mlmodel](https://github.com/edvardHua/PoseEstimationForMobile/blob/master/release/hourglass_model/hourglass.mlmodel)).~~
> `DEPRECATED`

ìœ„ ì €ì¥ì†ŒëŠ” ë‹«í˜”ìŠµë‹ˆë‹¤. ìš°ì„  ì•„ë˜ ëª¨ë¸ì„ ì‚¬ìš©í•´ì£¼ì„¸ìš”.
- [cpm](models/cpm_model)
- [hourglass](models/hourglass_model)

> input_name_shape_dict = {"image:0":[1,224,224,3]} image_input_names=["image:0"] <br>output_feature_names = ['Convolutional_Pose_Machine/stage_5_out:0']
>
> ï¼in [https://github.com/edvardHua/PoseEstimationForMobile](https://github.com/edvardHua/PoseEstimationForMobile)

#### ë©”íƒ€ì •ë³´

|                  | cpm                                      | hourglass          |
| ---------------- | ---------------------------------------- | ------------------ |
| Input shape      | `[1, 192, 192, 3]`                       | `[1, 192, 192, 3]` |
| Output shape     | `[1, 96, 96, 14]`                        | `[1, 48, 48, 14]`  |
| Input node name  | `image`                                  | `image`            |
| Output node name | `Convolutional_Pose_Machine/stage_5_out` | `hourglass_out_3`  |
| Model size       | 2.6 MB                                   | 2.0 MB             |

#### ì¶”ë¡ ì‹œê°„

|           | cpm    | hourglass |
| --------- | ------ | --------- |
| iPhone X  | 51 ms  | 49 ms     |
| iPhone 8+ | 49 ms  | 46 ms     |
| iPhone 6+ | 200 ms | 180 ms    |

## ë¹Œë“œ ì¤€ë¹„

### ëª¨ë¸ ê°€ì ¸ì˜¤ê¸°

![ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°.png](https://github.com/tucan9389/MobileNetApp-CoreML/blob/master/resource/%EB%AA%A8%EB%8D%B8%20%EB%B6%88%EB%9F%AC%EC%98%A4%EA%B8%B0.png?raw=true)

ëª¨ë¸ì„ ë„£ìœ¼ì…¨ìœ¼ë©´ ìë™ìœ¼ë¡œ ëª¨ë¸ ì´ë¦„ì˜ íŒŒì¼ì´ ë¹Œë“œê²½ë¡œ ì–´ë”˜ê°€ì— ìƒì„±ë©ë‹ˆë‹¤. ëª¨ë¸ì„ ì‚¬ìš©í• ë•ŒëŠ” ê²½ë¡œë¡œ ì ‘ê·¼í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ ëª¨ë¸ í´ë˜ìŠ¤ë¡œ ê°ì²´ë¥¼ ìƒì„±í•˜ì—¬ ì ‘ê·¼í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## ì½”ë“œ ì‘ì„±

#### 1. Vision í”„ë ˆì„í¬ ë¶ˆëŸ¬ì˜¤ê¸°

```swift
import Vision
```

#### 2. Core ML í”„ë¡œí¼í‹° ì„ ì–¸

```swift
typealias EstimationModel = model_cpm // model name(model_cpm) must be equal with mlmodel file name
var request: VNCoreMLRequest!
var visionModel: VNCoreMLModel!
```

#### 3. ëª¨ë¸ ì¤€ë¹„

```swift
override func viewDidLoad() {
    super.viewDidLoad()

    visionModel = try? VNCoreMLModel(for: EstimationModel().model)
	request = VNCoreMLRequest(model: visionModel, completionHandler: visionRequestDidComplete)
	request.imageCropAndScaleOption = .scaleFill
}

func visionRequestDidComplete(request: VNRequest, error: Error?) {
    /* ------------------------------------------------------ */
    /* something postprocessing what you want after inference */
    /* ------------------------------------------------------ */
}
```

#### 4. ì¶”ë¡  ğŸƒâ€â™‚ï¸

```swift
// on the inference point
let handler = VNImageRequestHandler(cvPixelBuffer: pixelBuffer)
try? handler.perform([request])
```

## Performance Test

### ëª¨ë¸ ê°€ì ¸ì˜¤ê¸°

You can download cpm or hourglass model for Core ML from [edvardHua/PoseEstimationForMobile](https://github.com/edvardHua/PoseEstimationForMobile) repo.

### ëª¨ë¸ ì´ë¦„ ë³€ê²½([`PoseEstimation_CoreMLTests.swift`](PoseEstimation-CoreMLTests/PoseEstimation_CoreMLTests.swift))

![fix-model-name-for-testing](/Users/canapio/Project/machine%20learning/MoT%20Labs/github_project/ml-ios-projects/PoseEstimation-CoreML/resource/fix-model-name-for-testing.png)

### í…ŒìŠ¤íŠ¸ ì‹¤í–‰

ë‹¨ì¶•í‚¤ë¡œëŠ” `âŒ˜ + U`ë¥¼ ëˆ„ë¥´ê±°ë‚˜  `Build for Testing` ì•„ì´ì½˜ì„ ëˆ„ë¥´ì„¸ìš”.

![build-for-testing](/Users/canapio/Project/machine%20learning/MoT%20Labs/github_project/ml-ios-projects/PoseEstimation-CoreML/resource/build-for-testing.png)

## í•¨ê»˜ ë³¼ ê²ƒ

- [motlabs/iOS-Proejcts-with-ML-Models](https://github.com/motlabs/iOS-Proejcts-with-ML-Models)<br>
  : TensorFlowë¡œ ë§Œë“  ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì„ iOSì—ì„œ ì‚¬ìš©í•´ë³´ëŠ” í”„ë¡œì íŠ¸ ëª¨ìŒ
- ~~[edvardHua/PoseEstimationForMobile](https://github.com/edvardHua/PoseEstimationForMobile)~~ -> `DEPRECATED` <br>
  : ëª¨ë°”ì¼ìš© Pose Estination TensorFlow í”„ë¡œì íŠ¸
- [tucan9389/FingertipEstimation-CoreML](https://github.com/tucan9389/FingertipEstimation-CoreML)<br>
  : [edvardHua/PoseEstimationForMobile](https://github.com/edvardHua/PoseEstimationForMobile)ë¥¼ ì´ìš©í•´ ë°ì´í„°ì…‹ë§Œ Fingertipìœ¼ë¡œ ë°”ê¾¸ì–´ í•™ìŠµì‹œí‚¨ ëª¨ë¸ì„ CoreMLì— ë§ì¶° êµ¬í˜„í•œ iOS í”„ë¡œì íŠ¸
